{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "with open(\"../Grounded-Segment-Anything/detect_results.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [x for x in os.listdir('ndh') if 'test' not in x]\n",
    "\n",
    "panos = {}\n",
    "for file in files:\n",
    "    path = os.path.join('../transform_format/ndh', file)\n",
    "    with open(path, 'r') as f:\n",
    "        ndh_data = json.load(f)\n",
    "        for ins in ndh_data:\n",
    "            scan = ins['scan']\n",
    "            end_panos = ins['end_panos']\n",
    "            target = ins['target']\n",
    "            instr_id = ins['instr_id']\n",
    "\n",
    "            keys = []\n",
    "            bboxes = []\n",
    "            scores = []\n",
    "            for end_pano in end_panos:\n",
    "                for idx in range(36):\n",
    "                    key = f'{scan}_{end_pano}_{target}_{idx}'\n",
    "                    if key in data:\n",
    "                        cands = data[key]\n",
    "                        for jdx in range(len(cands)):\n",
    "                            if data[key][jdx][1].split('(')[0] == target:\n",
    "                                keys.append(key)\n",
    "                                bboxes.append(data[key][jdx][0])\n",
    "                                scores.append(float(data[key][jdx][1].split('(')[1].split(')')[0]))       \n",
    "\n",
    "            if scores:\n",
    "                max_idx = scores.index(max(scores))\n",
    "                max_score = max(scores)\n",
    "                assert max_score == scores[max_idx]\n",
    "                max_key = keys[max_idx]\n",
    "                view_index = max_key.split('_')[-1]\n",
    "                view_pano = max_key.split('_')[1]\n",
    "                panos[instr_id] = f\"{scan}_{view_pano}_{view_index}\"\n",
    "            else:\n",
    "                if int(instr_id) < 850:\n",
    "                    panos[instr_id] = f\"ac26ZMwG7aT_0bd07b7213b245f8a54ec4010f6ef1cc_3\"\n",
    "                elif int(instr_id) < 2500:\n",
    "                    panos[instr_id] = f\"aayBHfsNo7d_5278ace992664bbcb69d686a7be2c3b3_6\"\n",
    "                elif int(instr_id) < 3500:\n",
    "                    panos[instr_id] = f\"EDJbREhghzL_a748d2c29b664cf0b256534cee04eb43_4\"\n",
    "                else:\n",
    "                    print(instr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Inpainting/captions.json\", \"r\") as f:\n",
    "    captions = json.load(f)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "def get_tokenizer():\n",
    "    cfg_name = 'bert-base-uncased'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg_name)\n",
    "    return tokenizer\n",
    "\n",
    "def encode_instr(tokenizer, instr):\n",
    "    max_instr_len = 100\n",
    "    instr_encoding = tokenizer.encode(instr, add_special_tokens=True)[:max_instr_len]\n",
    "    return instr_encoding\n",
    "\n",
    "def decode_instr(tokenizer, instr_encoding):\n",
    "    instr = tokenizer.decode(instr_encoding, skip_special_tokens=True)\n",
    "    return instr\n",
    "\n",
    "files = [x for x in os.listdir('new_ndh') if 'test' not in x]\n",
    "tok = get_tokenizer()\n",
    "for file in files:\n",
    "    path = os.path.join('../transform_format/new_ndh', file)\n",
    "    with open(path, 'r') as f:\n",
    "        cvdn_data = json.load(f)\n",
    "        for i, ins in enumerate(cvdn_data):\n",
    "            instr_id = ins['instr_id']\n",
    "            instr_enc = ins['instr_encoding']\n",
    "            instr = decode_instr(tok, instr_enc)\n",
    "            caption = captions[panos[instr_id]]\n",
    "            assert len(caption) == 1\n",
    "            new_instr = instr + '. That room has ' + caption[0] + '.'\n",
    "            new_instr_enc = encode_instr(tok, new_instr)\n",
    "            cvdn_data[i]['instr_encoding'] = new_instr_enc\n",
    "    \n",
    "    os.makedirs('cvdn_long', exist_ok=True)\n",
    "    with open(path.replace(\"new_ndh\", \"cvdn_long\"), 'w') as f:\n",
    "        json.dump(cvdn_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"utsd_captions.json\", \"r\") as f:\n",
    "    captions = json.load(f)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "def get_tokenizer():\n",
    "    cfg_name = 'bert-base-uncased'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg_name)\n",
    "    return tokenizer\n",
    "\n",
    "def encode_instr(tokenizer, instr):\n",
    "    max_instr_len = 100\n",
    "    instr_encoding = tokenizer.encode(instr, add_special_tokens=True)[:max_instr_len]\n",
    "    return instr_encoding\n",
    "\n",
    "def decode_instr(tokenizer, instr_encoding):\n",
    "    instr = tokenizer.decode(instr_encoding, skip_special_tokens=True)\n",
    "    return instr\n",
    "\n",
    "files = [x for x in os.listdir('new_ndh') if 'test' not in x]\n",
    "tok = get_tokenizer()\n",
    "for file in files:\n",
    "    path = os.path.join('../transform_format/new_ndh', file)\n",
    "    with open(path, 'r') as f:\n",
    "        cvdn_data = json.load(f)\n",
    "        for i, ins in enumerate(cvdn_data):\n",
    "            instr_id = str(ins['instr_id'])\n",
    "            instr_enc = ins['instr_encoding']\n",
    "            instr = decode_instr(tok, instr_enc)\n",
    "            caption = captions[instr_id]\n",
    "            assert len(caption) == 1\n",
    "            new_instr = instr + '. That room has ' + caption[0] + '.'\n",
    "            new_instr_enc = encode_instr(tok, new_instr)\n",
    "            cvdn_data[i]['instr_encoding'] = new_instr_enc\n",
    "    \n",
    "    os.makedirs('utsd_obj_long', exist_ok=True)\n",
    "    with open(path.replace(\"new_ndh\", \"utsd_obj_long\"), 'w') as f:\n",
    "        json.dump(cvdn_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marl",
   "language": "python",
   "name": "marl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
